---
title: "Building a Strokes Gained Model for Golf"
author: "Scott Flaska"
date: "2023-05-14"
draft: false
categories: [shotlink, golf, r, machine learning]
image: "images/predictions.png"
format: 
  html:
    toc: true
    toc-location: left
    toc-title: Contents
execute: 
  freeze: auto
---

# Introduction

Strokes Gained is an interesting method for evaluating golfers, co-created by Columbia Business School professor Mark Broadie.

```{=html}
<blockquote class="twitter-tweet" data-lang="en" data-theme="dark"><p lang="en" dir="ltr">Strokes Gained co-creator <a href="https://twitter.com/MarkBroadie?ref_src=twsrc%5Etfw">@markbroadie</a> illustrates the statistic using Justin Thomas&#39; final-round eagle at the 2021 <a href="https://twitter.com/hashtag/THEPLAYERS?src=hash&amp;ref_src=twsrc%5Etfw">#THEPLAYERS</a>. ðŸ”Ž <a href="https://t.co/LJ6qnp3ooE">pic.twitter.com/LJ6qnp3ooE</a></p>&mdash; Golf Channel (@GolfChannel) <a href="https://twitter.com/GolfChannel/status/1633598893706338305?ref_src=twsrc%5Etfw">March 8, 2023</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
```
From my understanding, Strokes Gained is similar to Expected Points Added (EPA) in football - golfers are evaluated against an "expected" number of strokes remaining after each shot. This "expected" value is based off a predictive model trained on historical data[^1]. In this post, I'll build an *expected strokes remaining* model using PGA ShotLink data, which can later be used to estimate strokes gained. The model will use features in the shot-level data to predict how many strokes remaining the golfer has before the shot.

[^1]: These methods have a major shortcoming in that they attribute the entire residual to a single golfer (or the teams involved). This could probably be corrected with a hierarchical/mixed model, but I'll save that for a future post.

# Data Preparation

First, I'll load the cleaned up data from my [previous post](https://scottflaska.github.io/blog/posts/02_shotlink_explore/).

```{r}
#| output: false
library(tidyverse)
library(tidymodels)
```

```{r}
shot_level <- readRDS("../02_shotlink_explore/shot_level.rds")
cut_colors <- readRDS("../02_shotlink_explore/cut_colors.rds")
```

Before I start building a model, I want to gain a better understanding of how penalties, drops, and provisionals are handled in the data. The `shot_type_s_p_d` column has this information (S = Shot, P = Penalty, D = Drop, Pr = Provisional).

```{r}
#Filter to holes where player's had at least 1 penalty/drop/provisional
shot_level %>% 
  mutate(is_p_d = ifelse(shot_type_s_p_d == 'S',0,1)) %>% 
  group_by(player,
           round,
           hole) %>% 
  mutate(p_d_count = sum(is_p_d)) %>% 
  filter(p_d_count > 0) %>% 
  ungroup() %>% 
  arrange(player,
          round,
          hole,
          shot) %>% 
  select(player,
         round,
         hole,
         shot,
         type = shot_type_s_p_d,
         strokes = num_of_strokes,
         yards_out = yards_out_before_shot,
         to_location) %>% 
  as.data.frame() %>% 
  head(14)
```

Reviewing the sample above, it looks like the `yards_out_before_shot` column (which will probably be the best predictor of strokes remaining) is a little misleading for penalty drops. For example, it looks like Player 6527 went in the water off the tee on the 6th Hole (Day 4), and had to take a penalty drop. The `yards_out_before_shot` value on the penalty and the drop is 20.25, but 70.11 on the first shot after the drop. This might be because ShotLink is measuring to where the ball landed in the water, but Player 6527 had to drop where they [entered the penalty area](https://www.usga.org/RulesFAQ/rules_answer.asp?FAQidx=210&Rule=0&Topic=4). For my model, I'll filter down to actual shots, where `shot_type_s_p_d = "S"`. I'll also add a `shot_id` so it will be easier to join back to the original data set later.

```{r}
shot_level <- shot_level %>%
  arrange(player,
          round,
          hole,
          shot) %>% 
  mutate(shot_id = row_number())

shots <- shot_level %>% 
  filter(shot_type_s_p_d == 'S')
```

# Linear Model

Now I'll take a look at how distance from the hole correlates to strokes remaining.

```{r}
#| warning: false
shots %>% 
  ggplot(mapping = aes(x = yards_out_before_shot,
                       y = strokes_remaining_before_shot)) +
  geom_jitter(width = 0,
              height = 0.1,
              alpha = 0.25) +
  geom_smooth(method = loess,
              se = FALSE) +
  scale_y_continuous(breaks = 1:10)

#Calculate R-Squared
cor(shots$yards_out_before_shot, 
    shots$strokes_remaining_before_shot)^2

```

While there is a certainly a strong correlation between these numbers, the relationship is not quite linear. A log transformation should clean this up.

```{r}
#| warning: false
shots <- shots %>% 
  mutate(log_yards_out_before_shot = log(yards_out_before_shot+1))
  

shots %>% 
  ggplot(mapping = aes(x = log_yards_out_before_shot,
                       y = strokes_remaining_before_shot)) +
  geom_jitter(width = 0,
              height = 0.1,
              alpha = 0.1) +
  geom_smooth(method = loess,
              se = FALSE) +
  scale_y_continuous(breaks = 1:10)

#Calculate R-Squared
cor(shots$log_yards_out_before_shot, 
    shots$strokes_remaining_before_shot)^2
```

The log transformation improves the R^2^ value, but it can probably be improved even further with a nonlinear model. To test this, I'll use cross-validation to evaluate out-of-sample performance. Ideally, I'd like to use some type of [time-series data splitting](https://topepo.github.io/caret/data-splitting.html#data-splitting-for-time-series) here to avoid any possible data leakage issues[^2], but I'll use a simpler method in this post. I'll split the 30 golfers into 10 groups of 3, and hold out one of these groups in the cross-validation process.

[^2]: If I wanted to use this model to predict strokes remaining for future shot's, I would want to make sure I'm not using future shots when training/evaluating my model.

```{r}
player_cv_groups <- shots %>% 
  select(player) %>% 
  unique() %>% 
  arrange(player) %>% 
  mutate(cv_group = cut_number(x = player, 
                               n = 10,
                               labels = FALSE))

shots <- shots %>% 
  inner_join(player_cv_groups,
             by = "player")

shots %>% 
  group_by(cv_group) %>% 
  summarize(golfers = n_distinct(player),
            shots = n())

folds <- group_vfold_cv(data = shots,
                        group = cv_group)

```

Now, using these folds, I'll find a performance baseline using the linear model above.

```{r}

just_log_yards_recipe <- recipe(formula = strokes_remaining_before_shot ~
                                  log_yards_out_before_shot, 
                                data = shots)

lm_mod <- linear_reg(mode = "regression",
                     engine = "lm")

lm_workflow <- workflow() %>%
  add_recipe(just_log_yards_recipe) %>%
  add_model(lm_mod)

lm_rs <- fit_resamples(object = lm_workflow,
                       resamples = folds,
                       control = control_resamples(save_pred = T))

lm_rs %>%
  collect_metrics() %>%
  select(.metric,
         mean) %>%
  as.data.frame()
```

As expected, the mean hold-out performance is very similar to the linear model fit on all the data.

# XGBoost Model

Next I'll try a gradient boosted tree model using the [XGBoost](https://xgboost.readthedocs.io/en/stable/) library. I love XGBoost. It trains and tunes relatively quickly, and you don't usually need to worry about other tedious pre-processing steps like centering, scaling, and imputing. Since XGBoost is nonlinear, I wont need to use the log transformation, and can switch back to just using `yards_out_before_shot`.

```{r}
#| warning: false
just_yards_recipe <- recipe(formula = strokes_remaining_before_shot ~
                              yards_out_before_shot, 
                            data = shots)

xgb_mod <- boost_tree(mode = "regression",
                      engine = "xgboost")

xgb_workflow <- workflow() %>%
  add_recipe(just_yards_recipe) %>%
  add_model(xgb_mod)

xgb_rs <- fit_resamples(object = xgb_workflow,
                        resamples = folds,
                        control = control_resamples(save_pred = T))

xgb_rs %>%
  collect_metrics() %>%
  select(.metric,
         mean) %>%
  as.data.frame()
```

The XGBoost model improves performance without any parameter tuning, so hopefully I can get more out of it. First, I'll look at the out-of-sample predictions,

```{r}
rs_preds <- xgb_rs %>% 
  collect_predictions() %>% 
  select(row_id = .row,
         fold = id,
         pred = .pred)

preds_join <- shots %>% 
  as.data.frame() %>% 
  mutate(row_id = row_number()) %>% 
  inner_join(rs_preds,
             by = "row_id") 

preds_join %>% 
  ggplot(mapping = aes(x = yards_out_before_shot,
                       y = pred,
                       color = fold)) +
  geom_point()
```

The fits look good, but the nonlinear warts are showing. This model only uses one feature, `yards_out_before_shot`, but the predictions vary significantly at the same distance. For example, looking at the shots around 200 yards out, the predictions vary from 2.8ish to 3.5ish. This will cause confusion when we start attributing strokes gained to specific shots.

# Monotonic Constraints

Luckily, there is a fix - XGBoost has the ability to enforce [monotonic constraints](https://xgboost.readthedocs.io/en/stable/tutorials/monotonic.html), meaning I can force predicted strokes remaining to increase as yards out increases. I'll retrain my model.

```{r}
#| warning: false
xgb_mod <- boost_tree(mode = "regression") %>% 
  set_engine(engine = "xgboost",
             monotone_constraints = c(1))

xgb_workflow <- workflow() %>%
  add_recipe(just_yards_recipe) %>%
  add_model(xgb_mod)

xgb_rs <- fit_resamples(object = xgb_workflow,
                        resamples = folds,
                        control = control_resamples(save_pred = T))

xgb_rs %>%
  collect_metrics() %>%
  select(.metric,
         mean) %>%
  as.data.frame()
```

The model performance actually improved slightly with the constraints, which is encouraging. Now I'll look at the out-of-sample predictions again.

```{r}
rs_preds <- xgb_rs %>% 
  collect_predictions() %>% 
  select(row_id = .row,
         fold = id,
         pred = .pred)

preds_join <- shots %>% 
  as.data.frame() %>% 
  mutate(row_id = row_number()) %>% 
  inner_join(rs_preds,
             by = "row_id") 

preds_join %>% 
  ggplot(mapping = aes(x = yards_out_before_shot,
                       y = pred,
                       color = fold)) +
  geom_point()
```

Much better! Another interesting finding is that there is a "jump" in the predictions around 260 yards. The predicted strokes remaining jump from 3.2ish to 3.5ish. This could be because it's near the range where PGA Tour players can take more aggressive shots at the green to reduce their score. This is a good demonstration of the value of nonlinear models.

# Ball Location Features

Next, I'd like to add some more features. I'll start with the ball location (fairway, green, etc.). I cleaned up ball location data in [my last post](https://scottflaska.github.io/blog/posts/02_shotlink_explore/#:~:text=The%20columns%20seem%20to%20match%20up%20pretty%20well%2C%20but%20I%E2%80%99d%20like%20to%20consolidate%20them%20into%20more%20general%20to_location%20column.), but those were the `to_location` columns. Here I need the `from_location` columns because I am using `strokes_remaining_before_shot` and `yards_out_before_shot`.

```{r}

shots %>% 
  group_by(from_location_scorer,
           from_location_laser) %>% 
  summarize(rows = n(),
            .groups = "keep") %>% 
  arrange(desc(rows)) %>% 
  as.data.frame()

shots <- shots %>% 
mutate(from_location = case_when(from_location_scorer == 'Green' 
                                 ~ 'Green',
                                 from_location_scorer == 'Tee Box' 
                                 ~ 'Tee Box',
                                 from_location_scorer %in% c('Fairway',
                                                             'Fringe') 
                                 ~ 'Fairway',
                                 from_location_scorer %in% c('Primary Rough',
                                                             'Intermediate Rough') 
                                 ~ 'Rough',
                                 from_location_scorer %in% c('Fairway Bunker',
                                                             'Green Side Bunker') 
                                 ~ 'Bunker',
                                 TRUE 
                                 ~ 'Other')) %>% 
  mutate(from_location = factor(from_location,
                                ordered = T,
                                levels = c("Green",
                                           "Fairway",
                                           "Tee Box",
                                           "Rough",
                                           "Bunker",
                                           "Other")))

shots %>% 
  filter(player == 1810,
         round == 1,
         hole %in% 1:3) %>%
  select(hole,
         shot,
         to_location,
         from_location) %>% 
  arrange(hole,
          shot) %>% 
  as.data.frame()
```

Now I'll train a new XGBoost model with this feature. Since I've updated the data set, I'll need to recreate the fold index and the recipe. I'll use [`step_dummy()`](https://recipes.tidymodels.org/reference/step_dummy.html) to convert `from_location` from a factor to binary terms for each location type.

```{r}
folds <- group_vfold_cv(data = shots,
                        group = cv_group)

with_location_recipe <- recipe(formula = strokes_remaining_before_shot ~
                                 yards_out_before_shot +
                                 from_location,
                               data = shots) %>% 
  step_dummy(from_location)

xgb_mod <- boost_tree() %>% 
  set_mode("regression") %>% 
  set_engine("xgboost",
             monotone_constraints = c(1)) %>% 
  translate()

xgb_workflow <- workflow() %>%
  add_recipe(with_location_recipe) %>%
  add_model(xgb_mod)

xgb_rs <- fit_resamples(object = xgb_workflow,
                        resamples = folds,
                        control = control_resamples(save_pred = T))

xgb_rs %>%
  collect_metrics() %>%
  select(.metric,
         mean) %>%
  as.data.frame()
```

Not much of an improvement, but the model got a little better.

```{r}
rs_preds <- xgb_rs %>% 
  collect_predictions() %>% 
  select(row_id = .row,
         fold = id,
         pred = .pred)

preds_join <- shots %>% 
  as.data.frame() %>% 
  mutate(row_id = row_number()) %>% 
  inner_join(rs_preds,
             by = "row_id") 

preds_join %>% 
  ggplot(mapping = aes(x = yards_out_before_shot,
                       y = pred,
                       color = from_location)) +
  geom_point() +
  scale_color_manual(values = cut_colors) + 
  labs(title = "Out-Of-Sample Predicted Strokes Remaining")
```

These new predictions make sense. Shots from the rough/bunker are harder and thus the predicted strokes remaining are higher. For example, at 100 yards, being in the rough (vs. fairway) increases expected strokes from 2.7ish to 3.0ish.

Adding these features increased the prediction "noise" at each distance - similar to the results of the unconstrained XGBoost model. This stems from the variation in how each sub-model handles the new features, and it goes away if I filter down to a single hold out set (Fold 1).

```{r}
preds_join %>% 
  filter(fold == 'Resample01') %>% 
  ggplot(mapping = aes(x = yards_out_before_shot,
                       y = pred,
                       color = from_location)) +
  geom_point() +
  scale_color_manual(values = cut_colors) + 
  labs(title = "Out-Of-Sample Predicted Strokes Remaining",
       subtitle = "Fold 1")
```

I could probably improve model performance with some parameter tuning, but I'll stop here for now.
