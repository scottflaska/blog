{
  "hash": "354884ae6d082d9730001a0b5c8c79cd",
  "result": {
    "markdown": "---\ntitle: \"Building a Strokes Gained Model for Golf\"\nauthor: \"Scott Flaska\"\ndate: \"2023-05-01\"\ndraft: true\ncategories: [shotlink, golf, r, machine learning]\nimage: \"\"\nformat: html\n---\n\n\nStrokes Gained is an interesting method for evaluating golfers, co-created by Columbia Business School professor Mark Broadie.\n\n\n```{=html}\n<blockquote class=\"twitter-tweet\" data-lang=\"en\" data-theme=\"dark\"><p lang=\"en\" dir=\"ltr\">Strokes Gained co-creator <a href=\"https://twitter.com/MarkBroadie?ref_src=twsrc%5Etfw\">@markbroadie</a> illustrates the statistic using Justin Thomas&#39; final-round eagle at the 2021 <a href=\"https://twitter.com/hashtag/THEPLAYERS?src=hash&amp;ref_src=twsrc%5Etfw\">#THEPLAYERS</a>. ðŸ”Ž <a href=\"https://t.co/LJ6qnp3ooE\">pic.twitter.com/LJ6qnp3ooE</a></p>&mdash; Golf Channel (@GolfChannel) <a href=\"https://twitter.com/GolfChannel/status/1633598893706338305?ref_src=twsrc%5Etfw\">March 8, 2023</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n```\n\nFrom my understanding, Strokes Gained is similar to Expected Points Added (EPA) in football - golfers are evaluated against an \"expected\" number of strokes remaining after each shot. This \"expected\" value is based off a predictive model trained on historical data[^1]. In this post, I'll build my own Strokes Gained model using PGA ShotLink data. The model will use features in the shot-level data to predict how many strokes remaining the golfer has before the shot.\n\n[^1]: These methods have a major shortcoming in that they attribute the entire residual to a single golfer (or the teams involved). This could probably be corrected with a hierarchical/mixed model, but I'll save that for a future post.\n\nFirst, I'll load the cleaned up data from my [previous post](https://scottflaska.github.io/blog/posts/02_shotlink_explore/).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(tidymodels)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nshot_level <- readRDS(\"../02_shotlink_explore/shot_level.rds\")\ncut_colors <- readRDS(\"../02_shotlink_explore/cut_colors.rds\")\n```\n:::\n\n\nBefore I start building a model, I want to get a better understanding of how penalties, drops, and provisionals are handled in the data. The `shot_type_s_p_d` column has this information (S = Shot, P = Penalty, D = Drop, Pr = Provisional).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Filter to holes where player's had at least 1 penalty/drop/provisional\nshot_level %>% \n  mutate(is_p_d = ifelse(shot_type_s_p_d == 'S',0,1)) %>% \n  group_by(player,\n           round,\n           hole) %>% \n  mutate(p_d_count = sum(is_p_d)) %>% \n  filter(p_d_count > 0) %>% \n  ungroup() %>% \n  arrange(player,\n          round,\n          hole,\n          shot) %>% \n  select(player,\n         round,\n         hole,\n         shot,\n         type = shot_type_s_p_d,\n         strokes = num_of_strokes,\n         yards_out = yards_out_before_shot,\n         to_location) %>% \n  as.data.frame() %>% \n  head(14)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   player round hole shot type strokes    yards_out to_location\n1    2206     2   18    1    S       1 238.00000000       Rough\n2    2206     2   18    2    D       0  13.16666667       Rough\n3    2206     2   18    3    S       1  15.11111111       Green\n4    2206     2   18    4    S       1   1.16666667        Hole\n5    6527     4    6    1    S       1 222.00000000       Water\n6    6527     4    6    2    P       1  20.25000000       Other\n7    6527     4    6    3    D       0  20.25000000       Other\n8    6527     4    6    4    S       1  70.11111111       Green\n9    6527     4    6    5    S       1   0.02777778        Hole\n10   6567     1    6    1    S       1 215.00000000       Water\n11   6567     1    6    2    P       1  13.27777778       Other\n12   6567     1    6    3    D       0  13.27777778       Other\n13   6567     1    6    4    S       1  73.36111111       Green\n14   6567     1    6    5    S       1   3.66666667        Hole\n```\n:::\n:::\n\n\nReviewing the sample above, it looks like the `yards_out_before_shot` column (which will probably be the best predictor of strokes remaining) is a little misleading for penalty drops. For example, t looks like Player 6527 went in the water off the tee on Day 4 6th Hole and had to take a penalty drop. The `yards_out_before_shot` value on the penalty and the drop is 20.25, but 70.11 on the first shot after the drop. This is probably because ShotLink is measuring to where the ball landed in the water, but Player 6527 had to drop where they [entered the penalty area](https://www.usga.org/RulesFAQ/rules_answer.asp?FAQidx=210&Rule=0&Topic=4). For my model, I'll filter down to actual shots, where `shot_type_s_p_d = \"S\"`. Before I do that, I'll add `x_before_shot` and `y_before_shot` columns which I'll use later.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshots <- shot_level %>% \n  group_by(player,\n           round,\n           hole) %>% \n  arrange(player,\n          round,\n          hole,\n          shot) %>% \n  mutate(x_before_shot = lag(x),\n         y_before_shot = lag(y)) %>% \n  ungroup() %>% \n  filter(shot_type_s_p_d == 'S')\n```\n:::\n\n\nNow I'll take a look at how distance from the hole correlates to strokes remaining.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshots %>% \n  ggplot(mapping = aes(x = yards_out_before_shot,\n                       y = strokes_remaining_before_shot)) +\n  geom_jitter(width = 0,\n              height = 0.1,\n              alpha = 0.25) +\n  geom_smooth(method = loess,\n              se = FALSE) +\n  scale_y_continuous(breaks = 1:10) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#Calculate R-Squared\ncor(shots$yards_out_before_shot, \n    shots$strokes_remaining_before_shot)^2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.682005\n```\n:::\n:::\n\n\nWhile there is a certainly a correlation between these numbers, the relationship is not quite linear. A log transformation should clean this up.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshots <- shots %>% \n  mutate(log_yards_out_before_shot = log(yards_out_before_shot+1))\n  \n\nshots %>% \n  ggplot(mapping = aes(x = log_yards_out_before_shot,\n                       y = strokes_remaining_before_shot)) +\n  geom_jitter(width = 0,\n              height = 0.1,\n              alpha = 0.1) +\n  geom_smooth(method = loess,\n              se = FALSE) +\n  scale_y_continuous(breaks = 1:10) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#Calculate R-Squared\ncor(shots$log_yards_out_before_shot, \n    shots$strokes_remaining_before_shot)^2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.7876248\n```\n:::\n:::\n\n\nThe log transformation improves the R^2^ value, but it can probably be improved even further with a nonlinear model. To test this, I'll use cross-validation to evaluate out-of-sample performance. Ideally, I'd like to use some type of [time-series data splitting](https://topepo.github.io/caret/data-splitting.html#data-splitting-for-time-series) here to avoid any possible data leakage issues[^2], but I'll use a simpler method in this post. To avoid over-fitting, I need to make sure I don't include shot's from the same golfer-hole in the training and hold-out data[^3]. I'll split the 30 golfers into 10 groups of 3, and hold out one of these groups in the cross-validation process.\n\n[^2]: If I wanted to use this model to predict strokes remaining for future shot's, I would want to make sure I'm not using future shots when training/evaluating my model.\n\n[^3]: If a player took a triple bogey on a hole, the model could look at the other shots for the player on that hole and see that there is likely going to be a higher score.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplayer_cv_groups <- shots %>% \n  select(player) %>% \n  unique() %>% \n  arrange(player) %>% \n  mutate(cv_group = cut_number(x = player, \n                               n = 10,\n                               labels = FALSE))\n\nshots <- shots %>% \n  inner_join(player_cv_groups,\n             by = \"player\")\n\nshots %>% \n  group_by(cv_group) %>% \n  summarize(golfers = n_distinct(player),\n            shots = n())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10 Ã— 3\n   cv_group golfers shots\n      <int>   <int> <int>\n 1        1       3   834\n 2        2       3   840\n 3        3       3   832\n 4        4       3   834\n 5        5       3   820\n 6        6       3   835\n 7        7       3   839\n 8        8       3   845\n 9        9       3   834\n10       10       3   835\n```\n:::\n\n```{.r .cell-code}\nfolds <- group_vfold_cv(data = shots,\n                        group = cv_group)\n```\n:::\n\n\nNow, using these folds, I'll find a performance baseline using the linear model above.\n\n\n::: {.cell}\n\n```{.r .cell-code}\njust_log_yards_recipe <- recipe(formula = strokes_remaining_before_shot ~ log_yards_out_before_shot, \n                                data = shots)\n\nlm_mod <- linear_reg(mode = \"regression\",\n                     engine = \"lm\")\n\nlm_workflow <- workflow() %>%\n  add_recipe(just_log_yards_recipe) %>%\n  add_model(lm_mod)\n\nlm_rs <- fit_resamples(object = lm_workflow,\n                       resamples = folds)\n\nlm_rs %>%\n  collect_metrics() %>%\n  select(.metric,\n         mean) %>%\n  as.data.frame()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  .metric      mean\n1    rmse 0.5569516\n2     rsq 0.7900181\n```\n:::\n:::\n\n\nAs expected, the mean hold-out performance is very similar to the linear model fit on all the data.\n\nNext I'll try a gradient boosted tree model using the [xgboost](https://xgboost.readthedocs.io/en/stable/) library. I love xgboost. It trains and tunes relatively quickly, and you don't usually need to worry about other tedious pre-processing steps like centering, scaling, and imputing.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nxgb_mod <- boost_tree(mode = \"regression\",\n                      engine = \"xgboost\")\n\nxgb_workflow <- workflow() %>%\n  add_recipe(just_log_yards_recipe) %>%\n  add_model(xgb_mod)\n\nxgb_rs <- fit_resamples(object = xgb_workflow,\n                        resamples = folds)\n\nxgb_rs %>%\n  collect_metrics() %>%\n  select(.metric,\n         mean) %>%\n  as.data.frame()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  .metric      mean\n1    rmse 0.5237023\n2     rsq 0.8142559\n```\n:::\n:::\n\n\nThe xgboost model improves performance without any parameter tuning, so I'll stick with it for now.\n\nNext, I'd like to add some more features. I'll start with the ball location (fairway, green, etc.). I cleaned up ball location data in [my last post](https://scottflaska.github.io/blog/posts/02_shotlink_explore/#:~:text=The%20columns%20seem%20to%20match%20up%20pretty%20well%2C%20but%20I%E2%80%99d%20like%20to%20consolidate%20them%20into%20more%20general%20to_location%20column.), but those were the `to_location` columns. Here I need the `from_location` columns because I am using `strokes_remaining_before_shot` and `yards_out_before_shot` . Rather than clean these columns, I'll use `dplyr::lag()` to grab the `to_location` from the previous shot.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshots <- shots %>% \n  group_by(player,\n           round,\n           hole) %>% \n  arrange(shot) %>% \n  mutate(from_location = lag(to_location)) %>% \n  ungroup() %>% \n  mutate(from_location = ifelse(shot == 1, 'Tee Box', from_location)) %>% \n  mutate(from_location = factor(from_location,\n                                levels = c(\"Tee Box\",\n                                           \"Rough\",\n                                           \"Green\",\n                                           \"Fairway\",\n                                           \"Other\",\n                                           \"Bunker\",\n                                           \"Water\",\n                                           \"Hole\")))\n\nshots %>% \n  filter(player == 1810,\n         round == 1,\n         hole %in% 1:3) %>%\n  select(hole,\n         shot,\n         to_location,\n         from_location) %>% \n  arrange(hole,\n          shot) %>% \n  as.data.frame()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   hole shot to_location from_location\n1     1    1       Rough       Tee Box\n2     1    2       Green         Rough\n3     1    3       Green         Green\n4     1    4        Hole         Green\n5     2    1       Green       Tee Box\n6     2    2        Hole         Green\n7     3    1     Fairway       Tee Box\n8     3    2       Green       Fairway\n9     3    3       Green         Green\n10    3    4        Hole         Green\n```\n:::\n:::\n\n\nNow I'll train a new xgboost model with this feature. I'll switch back to using `yards_out_before_shot` instead of `log_yards_out_before_shot` since xgboost is nonlinear, it should not have much impact on model performance. Since I've updated the data set, I'll need to recreate the fold index and the recipe.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfolds <- group_vfold_cv(data = shots,\n                        group = cv_group)\n\nwith_location_recipe <- recipe(formula = strokes_remaining_before_shot ~\n                                 yards_out_before_shot +\n                                 from_location,\n                               data = shots) %>% \n  step_dummy(from_location)\n\nxgb_mod <- boost_tree(mode = \"regression\",\n                      engine = \"xgboost\")\n\nxgb_workflow <- workflow() %>%\n  add_recipe(with_location_recipe) %>%\n  add_model(xgb_mod)\n\nxgb_rs <- fit_resamples(object = xgb_workflow,\n                        resamples = folds)\n\nxgb_rs %>%\n  collect_metrics() %>%\n  select(.metric,\n         mean) %>%\n  as.data.frame()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  .metric      mean\n1    rmse 0.5166006\n2     rsq 0.8192588\n```\n:::\n:::\n\n\nNot much of an improvement, but the model got a little better\n\nNext, I'd like to add a feature that uses the results of nearby shots.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nround_hole_ids <- shots %>% \n  select(round,\n         hole) %>% \n  unique() %>% \n  arrange(round,\n          hole) %>% \n  mutate(round_hole_id = row_number())\n\nget_knn_preds <- function(id = 1,\n                          round_hole_ids,\n                          shots) {\n  \n  round_hole_shots <- round_hole_ids %>% \n    filter(round_hole_id == id) %>% \n    inner_join(shots,\n               by = c('round','hole')) %>% \n    filter(!is.na(x_before_shot)) %>% \n    select(player,\n           round,\n           hole,\n           shot,\n           cv_group,\n           x_before_shot,\n           y_before_shot,\n           strokes_remaining_before_shot)\n  \n  # round_hole_shots %>% \n  #   mutate(strokes_remaining_before_shot = factor(strokes_remaining_before_shot,\n  #                                               ordered = T)) %>%\n  #   ggplot(mapping = aes(x = x_before_shot,\n  #                        y = y_before_shot,\n  #                        color = strokes_remaining_before_shot)) +\n  #   geom_point() +\n  #   coord_equal() +\n  #   theme_minimal()\n  \n  knn_folds <- group_vfold_cv(data = round_hole_shots,\n                              group = cv_group)\n  \n  knn_recipe <- recipe(formula = strokes_remaining_before_shot ~\n                         x_before_shot +\n                         y_before_shot,\n                       data = round_hole_shots)\n  \n  knn_mod <- nearest_neighbor(mode = \"regression\",\n                              engine = \"kknn\")\n  \n  knn_workflow <- workflow() %>%\n    add_recipe(knn_recipe) %>%\n    add_model(knn_mod)\n  \n  knn_rs <- fit_resamples(object = knn_workflow,\n                          resamples = knn_folds,\n                          control = control_resamples(save_pred = T))\n  \n  rs_preds <- knn_rs %>% \n    collect_predictions() %>% \n    select(row_id = .row,\n           pred = .pred)\n  \n  preds_join <- round_hole_shots %>% \n    as.data.frame() %>% \n    mutate(row_id = row_number()) %>% \n    inner_join(rs_preds,\n               by = \"row_id\") %>% \n    select(player,\n           round,\n           hole,\n           shot,\n           knn_pred = pred)\n  \n  return(preds_join)\n} \n\nknn_preds_long <- round_hole_ids$round_hole_id %>% \n  map(.f = get_knn_preds,\n      round_hole_ids,\n      shots) %>% \n  bind_rows()\n\nsaveRDS(knn_preds_long, file = \"knn_preds_long.rds\")\n```\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nshots <- shots %>% \n  left_join(knn_preds_long,\n            by = c('player','round','hole','shot'))\n\nshots %>% \n  ggplot(mapping = aes(x = knn_pred,\n                       y = strokes_remaining_before_shot)) +\n  geom_jitter()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfolds <- group_vfold_cv(data = shots,\n                        group = cv_group)\n\nwith_knn_recipe <- recipe(formula = strokes_remaining_before_shot ~\n                            yards_out_before_shot +\n                            from_location +\n                            knn_pred,\n                          data = shots) %>% \n  step_dummy(from_location)\n\nxgb_mod <- boost_tree(mode = \"regression\",\n                      engine = \"xgboost\")\n\nxgb_workflow <- workflow() %>%\n  add_recipe(with_knn_recipe) %>%\n  add_model(xgb_mod)\n\nxgb_rs <- fit_resamples(object = xgb_workflow,\n                        resamples = folds)\n\nxgb_rs %>%\n  collect_metrics() %>%\n  select(.metric,\n         mean) %>%\n  as.data.frame()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  .metric      mean\n1    rmse 0.5176478\n2     rsq 0.8185528\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# nearby_shots <- shots %>% \n#   filter(!is.na(x_before_shot)) %>% \n#   select(player,\n#          cv_group,\n#          round,\n#          hole,\n#          shot,\n#          x_before_shot,\n#          y_before_shot,\n#          strokes_remaining_before_shot) \n# \n# nearby_shots_join <- nearby_shots %>% \n#   left_join(nearby_shots,\n#             by = \"hole\",\n#             suffix = c(\"_a\",\"_b\")) %>% \n#   filter(cv_group_a != cv_group_b) %>% \n#   mutate(dist_a_b = sqrt((x_before_shot_a-x_before_shot_b)^2 + (y_before_shot_a-y_before_shot_b)^2)) %>%\n#   mutate(dist_a_b = dist_a_b/3)\n# \n# nearby_shot_example = nearby_shots_join %>% \n#   filter(player_a == 1810,\n#          round_a == 1,\n#          hole == 1,\n#          shot_a == 2)\n# \n# nearby_shot_example %>% \n#   mutate(strokes_remaining_before_shot_b = factor(strokes_remaining_before_shot_b,\n#                                                   ordered = TRUE)) %>% \n#   ggplot(mapping = aes(x = x_before_shot_b,\n#                        y = y_before_shot_b,\n#                        color = strokes_remaining_before_shot_b,\n#                        size = 1/dist_a_b)) +\n#   geom_point() +\n#   coord_equal()\n# \n# nearby_shots_join %>% \n#   filter(dist_a_b <= 10) %>% \n#   mutate(weight = 1/dist_a_b) %>% \n#   mutate(weighted_strokes = weight*strokes_remaining_before_shot_b) %>%\n#   group_by(player_a,\n#            hole,\n#            round_a,\n#            shot_a,\n#            strokes_remaining_before_shot_a) %>% \n#   summarize(avg_strokes = mean(strokes_remaining_before_shot_b),\n#             total_weight = sum(weight),\n#             total_weighted_strokes = sum(weighted_strokes),\n#             .groups = \"keep\") %>% \n#   mutate(weighted_avg = total_weighted_strokes/total_weight) %>% \n#   ggplot(mapping = aes(x = weighted_avg,\n#                        y = strokes_remaining_before_shot_a)) +\n#   geom_jitter()\n# \n# # nearby_shots_example <- nearby_shots_join %>% \n# #   filter(player_a == 1810,\n# #          round_a == 1,\n# #          hole == 1,\n# #          ) %>% \n# #   mutate(include = ifelse(dist_a_b <= 15,\"yes\",\"no\"))\n# # \n# # nearby_shots_example %>% \n# #   ggplot() +\n# #   geom_point(mapping = aes(x = x_before_shot_b,\n# #                            y = y_before_shot_b))\n# # \n# # subset <- nearby_shots_example %>%\n# #   filter(include == 'yes') %>% \n# #   arrange(dist_a_b) %>%\n# #   select(dist_a_b,\n# #          strokes_remaining_after_shot_b) %>% \n# #   mutate(weight = 1/dist_a_b) %>% \n# #   mutate(weighted_strokes = weight*strokes_remaining_after_shot_b)\n# # \n# # subset\n# # \n# # subset %>% \n#   summarize(avg_strokes = mean(strokes_remaining_after_shot_b),\n#             total_weight = sum(weight),\n#             weighted_strokes = sum(weighted_strokes)) %>%\n# #   mutate(weighted_avg = weighted_strokes/total_weight)\n# #   \n# # \n# # nearby_shots_join %>% \n# #   select(hole,)\n```\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}